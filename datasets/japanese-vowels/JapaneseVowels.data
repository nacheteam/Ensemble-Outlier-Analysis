<!------------------------------------------------------------------------
<!  Japanese vowels 
<!----------------------------------------------------------------------->
<HTML>
<HEAD>
<TITLE>Japanese vowels</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF">

<!------------------------------------------------------------------------
<!  Title 
<!----------------------------------------------------------------------->
<H1>Japanese vowels</H1>

<!------------------------------------------------------------------------
<!  Data Type 
<!----------------------------------------------------------------------->
<H2>Data Type</H2>
multivariate time series. 

<!------------------------------------------------------------------------
<!  Abstract
<!----------------------------------------------------------------------->
<H2>Abstract</H2>
<p>
This dataset records 640 time series of 12 LPC cepstrum coefficients taken from nine male speakers.
</p>

<!------------------------------------------------------------------------
<!  Sources
<!----------------------------------------------------------------------->
<H2> Sources</H2>
<H4> Original Owner and Donor</H4>
<PRE>
Mineichi Kudo, Jun Toyama, Masaru Shimbo
<a href="http://ips9.main.eng.hokudai.ac.jp/index_e.html">Information Processing Laboratory</a>
Division of Systems and Information Engineering
Graduate School of Engineering
Hokkaido University, Sapporo 060-8628, JAPAN
{<a href="mailto:mine@main.eng.hokudai.ac.jp">mine</a>,<a href="mailto:jun@main.eng.hokudai.ac.jp">jun</a>,<a href="mailto:shimbo@main.eng.hokudai.ac.jp">shimbo</a>}@main.eng.hokudai.ac.jp
</PRE>
<B>Date Donated: </B> June 13, 2000 


<!------------------------------------------------------------------------
<!  Data Characteristics 
<!----------------------------------------------------------------------->
<H2> Data Characteristics</H2>

<p>
The data was collected for examining our newly developed classifier for multidimensional curves (multidimensional time series). Nine male speakers uttered two Japanese vowels /ae/ successively. For each utterance, with the analysis parameters described below, we applied 12-degree linear prediction analysis to it to obtain a discrete-time series with 12 LPC cepstrum coefficients. This means that one utterance by a speaker forms a time series whose length is in the range 7-29 and each point of a time series is of 12 features (12 coefficients).

<p>
The number of the time series is 640 in total. We used one set of 270 time series for training and the other set of 370 time series for testing.


<h4>Number of Instances (Utterances)</h4>
<ul>
  <li>Training: 270  (30 utterances by 9 speakers. See file 'size_ae.train'.)
  <li>Testing: 370  (24-88 utterances by the same 9 speakers in different opportunities. See file 'size_ae.test'.)
</ul>

<h4>Length of Time Series</h4>
<ul>
  <li>7 - 29 depending on utterances
</ul>

<h4>Number of Attributes</h4>
<ul>
  <li>12 real values
</ul>

<h4>Analysis parameters</h4>
<ul>
  <li>Sampling rate : 10kHz
  <li>Frame length  : 25.6 ms
  <li>Shift length  :  6.4ms
  <li>Degree of LPC coefficients : 12
</ul>



<!------------------------------------------------------------------------
<!  Data Format 
<!----------------------------------------------------------------------->
<H2>Data Format</H2>

<h4>Files</h4>
<ul>
  <li>Training file: ae.train
  <li>Testing file: ae.test
</ul>

<h4>Format</h4>
<p>
Each line in ae.train or ae.test represents 12 LPC coefficients in the increasing order separated by spaces. This corresponds to one analysis frame.

<p>
Lines are organized into blocks, which are a set of 7-29 lines separated by blank lines and corresponds to a single speech utterance of /ae/ with 7-29 frames.

<p>
Each speaker is a set of consecutive blocks. In ae.train there are 30 blocks for each speaker. Blocks 1-30 represent speaker 1, blocks 31-60 represent speaker 2, and so on up to speaker 9. In ae.test, speakers 1 to 9 have the corresponding number of blocks: 31 35 88 44 29 24 40 50 29. Thus, blocks 1-31 represent speaker 1 (31 utterances of /ae/), blocks 32-66 represent speaker 2 (35 utterances of /ae/), and so on. 
                 

<!------------------------------------------------------------------------
<!  Past Usage 
<!----------------------------------------------------------------------->
<H2>Past Usage</H2>
<p>
M. Kudo, J. Toyama and M. Shimbo. (1999). "Multidimensional Curve Classification Using Passing-Through Regions". Pattern Recognition Letters, Vol. 20, No. 11--13, pages 1103--1111.


<!------------------------------------------------------------------------
<!  Acknowledgements 
<!----------------------------------------------------------------------->
<H2> Acknowledgements, Copyright Information, and Availability</H2>

<p>
If you publish any work using the dataset, please inform the donor. 
Use for commercial purposes requires donor permission. 


<!------------------------------------------------------------------------
<!  References 
<!----------------------------------------------------------------------->
<H2>References and Further Information</H2>

<p>
Similar data are available for different utterances 
/ei/, /iu/, /uo/, /oa/ in addition to /ae/.
Please contact the donor if you are interested in using this data.


<!------------------------------------------------------------------------
<!  Signature
<!----------------------------------------------------------------------->
<p>
<hr>
<ADDRESS>
<A href="http://kdd.ics.uci.edu/">The UCI KDD Archive</A><br>
<a href="http://www.ics.uci.edu/">Information and Computer Science</a><br>
<a href="http://www.uci.edu/">University of California, Irvine</a><br>
Irvine, CA 92697-3425 <br> 
</ADDRESS> 
Last modified: June 14, 2000</BODY>
</HTML>

